{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"6rx_6gkH5VHX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716770107617,"user_tz":-480,"elapsed":42611,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"e74288ca-bf45-4b2e-d8e7-46fcbcb674f9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/csa/CSA3')\n","os.getcwd()"],"metadata":{"id":"gc6tdAyZ5ZJn","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1716770107617,"user_tz":-480,"elapsed":7,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"26a08018-a15a-45e1-cee3-dc464f1d1989"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/csa/CSA3'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["def loadmodel_set(load_epoch):\n","  class Opion():\n","    def __init__(self):\n","        self.dataroot= r'I:\\irregular holes\\paris_eval_gt' #image dataroot\n","        self.maskroot= r'I:\\irregular holes\\testing_mask_dataset'#mask dataroot\n","        self.batchSize= 1   # Need to be set to 1\n","        self.fineSize=256 # image size\n","        self.input_nc=3  # input channel size for first stage\n","        self.input_nc_g=6 # input channel size for second stage\n","        self.output_nc=3# output channel size\n","        self.ngf=64 # inner channel\n","        self.ndf=64# inner channel\n","        self.which_model_netD='basic' # patch discriminator\n","        self.which_model_netF='feature'# feature patch discriminator\n","        self.which_model_netG='unet_csa'# seconde stage network\n","        self.which_model_netP='unet_256'# first stage network\n","        self.triple_weight=1\n","        self.name='CSA_inpainting'\n","        self.n_layers_D='3' # network depth\n","        self.gpu_ids=[0]\n","        self.model='csa_net'\n","        self.checkpoints_dir=r'.\\checkpoints' #\n","        self.norm='instance'\n","        self.fixed_mask=1\n","        self.use_dropout=False\n","        self.init_type='normal'\n","        self.mask_type='random'\n","        self.lambda_A=100\n","        self.threshold=5/16.0\n","        self.stride=1\n","        self.shift_sz=1 # size of feature patch\n","        self.mask_thred=1\n","        self.bottleneck=512\n","        self.gp_lambda=10.0\n","        self.ncritic=5\n","        self.constrain='MSE'\n","        self.strength=1\n","        self.init_gain=0.02\n","        self.cosis=1\n","        self.gan_type='lsgan'\n","        self.gan_weight=0.2\n","        self.overlap=4\n","        self.skip=0\n","        self.display_freq=1000\n","        self.print_freq=50\n","        self.save_latest_freq=5000\n","        self.save_epoch_freq=2\n","        self.continue_train=False\n","        self.epoch_count=1\n","        self.phase='train'\n","        self.which_epoch='6'\n","        self.niter=20\n","        self.niter_decay=100\n","        self.beta1=0.5\n","        self.lr=0.0002\n","        self.lr_policy='lambda'\n","        self.lr_decay_iters=50\n","        self.isTrain=True\n","  from util.data_load import Data_load\n","  from models.models import create_model\n","  import torch\n","  import os\n","  import torchvision\n","  from torch.utils import data\n","  import torchvision.transforms as transforms\n","  opt = Opion()\n","  model = create_model(opt)\n","  total_steps = 0\n","\n","  model.load(load_epoch)\n","  print('load model successfully!')\n","  return model"],"metadata":{"id":"0IXEX-R2bJYn","executionInfo":{"status":"ok","timestamp":1716770107617,"user_tz":-480,"elapsed":4,"user":{"displayName":"郝赟","userId":"01912104721301990604"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def loadimg(data_path, mask_path):\n","  from util.data_load import Data_load\n","  import torchvision.transforms as transforms\n","  from torch.utils import data\n","  transform_mask = transforms.Compose(\n","      [transforms.Resize((256,256)),\n","      transforms.ToTensor(),\n","      ])\n","  transform = transforms.Compose(\n","      [\n","      transforms.Resize((256,256)),\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)])\n","\n","  dataset_train = Data_load(data_path, mask_path, transform, transform_mask)\n","  iterator_train = (data.DataLoader(dataset_train, batch_size=1))\n","  print(len(dataset_train))\n","  return iterator_train"],"metadata":{"id":"aobIulljiI46","executionInfo":{"status":"ok","timestamp":1716770112025,"user_tz":-480,"elapsed":2,"user":{"displayName":"郝赟","userId":"01912104721301990604"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"id":"DW3igBoNaz6f","executionInfo":{"status":"ok","timestamp":1716770114487,"user_tz":-480,"elapsed":2,"user":{"displayName":"郝赟","userId":"01912104721301990604"}}},"outputs":[],"source":["def inpaint(iterator_test,model,height,width):\n","  import time\n","  import torch\n","  import torchvision\n","  import os\n","  import numpy as np\n","  import torchvision.transforms as transforms\n","\n","  from skimage.metrics import structural_similarity as SSIM\n","  from skimage.metrics import peak_signal_noise_ratio as PSNR\n","  from skimage.metrics import mean_squared_error as MSE\n","  import cv2\n","\n","  total_psnr = [0]*200\n","  total_ssim = [0]*200\n","  total_mse = [0]*200\n","  save_dir = \"./content/fin\"\n","  if os.path.exists(save_dir) is False:\n","      os.makedirs(save_dir)\n","\n","  epoch=1\n","  i=0\n","  for image, mask in (iterator_test):\n","      iter_start_time = time.time()\n","      image=image.cuda()\n","      mask=mask.cuda()\n","      mask=mask[0][0]\n","      mask=torch.unsqueeze(mask,0)\n","      mask=torch.unsqueeze(mask,1)\n","      mask=mask.byte()\n","\n","      model.set_input(image,mask)\n","      model.set_gt_latent()\n","      model.test()\n","      print(\"fix\")\n","      real_A,real_B,fake_B=model.get_current_visuals()\n","      pic = (torch.cat([real_A, real_B,fake_B], dim=0) + 1) / 2.0\n","      torchvision.utils.save_image(pic, '%s/Epoch_(%d).jpg' % (\n","      save_dir, epoch), nrow=1)\n","      #fake_B = (torch.cat([fake_B], dim=0) + 1) / 2.0\n","      retransform = transforms.Compose(\n","        [\n","        transforms.Resize((height,width))]\n","        )\n","      fake_B = retransform(fake_B)\n","      fake_B = (fake_B * 0.5) + 0.5\n","\n","      real_B = retransform(real_B)\n","      #real_B = (real_B * 0.5) + 0.5\n","      real_B = (torch.cat([real_B], dim=0) + 1) / 2.0\n","\n","      real_A = retransform(real_A)\n","      #real_B = (real_B * 0.5) + 0.5\n","      real_A = (torch.cat([real_A], dim=0) + 1) / 2.0\n","\n","      torchvision.utils.save_image(fake_B, '%s/re.jpg' % (\n","      save_dir), nrow=1)\n","      torchvision.utils.save_image(real_B, '%s/re1.jpg' % (\n","      save_dir), nrow=1)\n","      torchvision.utils.save_image(real_A, '%s/break.jpg' % (\n","      save_dir), nrow=1)\n","\n","      #参数评价\n","      #img_cp1 = cv2.imread(\"/content/fin/re.jpg\")\n","      #img_cp2 = cv2.imread(\"/content/fin/re1.jpg\")\n","      #psnr = PSNR(img_cp1, img_cp2)\n","      #ssim = SSIM(img_cp1, img_cp2, multichannel=True, channel_axis=2)\n","      #mse = MSE(img_cp1, img_cp2)\n","      #total_psnr[i] = psnr\n","      #total_ssim[i] = ssim\n","      #total_mse[i] = mse\n","      #i=i+1\n","  #print(\"psnr\")\n","  #print(np.mean(total_psnr))\n","  #print(\"ssim\")\n","  #print(np.mean(total_ssim))\n","  #print(\"mse\")\n","  #print(np.mean(total_mse))\n","  return fake_B\n","\n"]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import PIL\n","from PIL import Image, ImageOps\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","img_path = \"./testimg/real/test0.jpg\"\n","nomask_path = \"./testimg/nomask/0.png\"\n","IMAGE_UPLOAD_PATH = \"./testimg/real\"\n","MASK_PATH = \"./testimg/mask1\"\n","noMASK_PATH = \"./testimg/mask\"\n","save_path = \"./testimg/fin\"\n","\n","\n","def restore_image(model, image_or, mask=None):\n","    if mask is not None:\n","      #mask = mask['layers'][0]\n","      data_path = IMAGE_UPLOAD_PATH\n","      mask_path = MASK_PATH\n","      iterator_test = loadimg(data_path, mask_path)\n","      #model = loadmodel_set(30)\n","      repaired_image=inpaint(iterator_test,model)\n","      width = image_or.width\n","      height = image_or.height\n","      retransform = transforms.Compose(\n","        [\n","        transforms.Resize((height,width))]\n","        )\n","      repaired_image = retransform(repaired_image)\n","      repaired_image = (repaired_image * 0.5) + 0.5\n","    else:\n","      #mask = Image.new(\"L\", (512, 512), color=0)\n","      #cv2.imwrite(nomask_path, mask)\n","      #mask.save(nomask_path)\n","      data_path = IMAGE_UPLOAD_PATH\n","      mask_path = noMASK_PATH\n","      iterator_test = loadimg(data_path, mask_path)\n","      #model = loadmodel_set(30)\n","      repaired_image=inpaint(iterator_test,model)\n","      width = image_or.width\n","      height = image_or.height\n","      retransform = transforms.Compose(\n","        [transforms.RandomHorizontalFlip(),\n","        transforms.Resize((height,width))]\n","        )\n","      repaired_image = retransform(repaired_image)\n","      repaired_image = (repaired_image * 0.5) + 0.5\n","    return repaired_image\n","\n","def restore_image1(model, image_or, mask):\n","  iterator_test = loadimg(image_or, mask)\n","  width = image_or.width\n","  height = image_or.height\n","  repaired_image=inpaint(iterator_test,model,height,width)\n","  #torchvision.utils.save_image(repaired_image, '%s/re.jpg' % (save_path), nrow=1)\n","  repaired_image = Image.open(\"/content/fin/re.jpg\")\n","  #return repaired_image\n","  #torchvision.utils.save_image(repaired_image, '%s/re.jpg' % (save_path), nrow=1)\n","  return repaired_image\n","def restore_image2(model, image_or, mask):\n","  iterator_test = loadimg(image_or, mask)\n","  repaired_image=inpaint(iterator_test,model,218,178)\n","  repaired_image = Image.open(\"./content/fin/re.jpg\")\n","  return repaired_image"],"metadata":{"id":"MZ8vMslV_vB0","executionInfo":{"status":"ok","timestamp":1716770123078,"user_tz":-480,"elapsed":6891,"user":{"displayName":"郝赟","userId":"01912104721301990604"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from skimage.metrics import structural_similarity as SSIM\n","from skimage.metrics import peak_signal_noise_ratio as PSNR\n","from skimage.metrics import mean_squared_error as MSE\n","import cv2\n","\n","def get_spm(img_cp1, img_cp2):\n","\n","    psnr = PSNR(img_cp1, img_cp2)\n","    ssim = SSIM(img_cp1, img_cp2, multichannel=True, channel_axis=2)\n","    mse = MSE(img_cp1, img_cp2)\n","    return psnr, ssim, mse\n","\n","#img_cp1 = cv2.imread(\"./testimg/fin/re.jpg\")\n","#img_cp2 = cv2.imread(\"./testimg/real/test.jpg\")\n","img_cp1 = cv2.imread(\"/content/fin/re.jpg\")\n","img_cp2 = cv2.imread(\"/content/fin/re1.jpg\")\n","psnr, ssim, mse = get_spm(img_cp1, img_cp2)\n","print(\"PSNR:{}\\nSSIM:{}\\nMSE:{}\".format(psnr, ssim, mse))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"pYtceBEZa9en","executionInfo":{"status":"error","timestamp":1715525795870,"user_tz":-480,"elapsed":3,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"8c42def4-8ccf-4e8f-e6c7-9a413fd597eb"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-23019c4a1aa8>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimg_cp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/fin/re.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mimg_cp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/fin/re1.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpsnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_cp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PSNR:{}\\nSSIM:{}\\nMSE:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-23019c4a1aa8>\u001b[0m in \u001b[0;36mget_spm\u001b[0;34m(img_cp1, img_cp2)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_spm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_cp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpsnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPSNR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_cp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mssim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSIM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_cp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_cp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/metrics/simple_metrics.py\u001b[0m in \u001b[0;36mpeak_signal_noise_ratio\u001b[0;34m(image_true, image_test, data_range)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mcheck_shape_equality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_range\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mcheck_shape_equality\u001b[0;34m(im1, im2)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_shape_equality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;34m\"\"\"Raise an error if the shape do not match.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input images must have the same dimensions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}]},{"cell_type":"code","source":["model = loadmodel_set(6)\n","#model_CA = loadmodel_set(30)\n","#model_SH = loadmodel_set(32)\n","#model_CSAF = loadmodel_set(2)"],"metadata":{"id":"psad7BJIiSyD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = restore_image2(model_CA,image_path,mask_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"p_nAIdHT3Wuk","executionInfo":{"status":"error","timestamp":1715775827194,"user_tz":-480,"elapsed":598,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"62a6086c-51e0-42e4-9814-fab38de6998c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model_CA' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-d99604cb9466>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_image2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_CA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model_CA' is not defined"]}]},{"cell_type":"code","source":["img = restore_image2(model_SH,image_path,mask_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HvXp74rd3ZyN","executionInfo":{"status":"ok","timestamp":1715436855663,"user_tz":-480,"elapsed":617,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"66395581-12bd-4cbc-bf6a-623a61662e0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","psnr\n","0.13977687910702202\n","ssim\n","0.004689703636456226\n","mse\n","0.520610332268151\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-b43277043ffe>:64: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n","  ssim = SSIM(img_cp1, img_cp2, multichannel=True, channel_axis=2)\n"]}]},{"cell_type":"code","source":["img = restore_image2(model_CSAF,image_path,mask_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIQQPE9z3a4a","executionInfo":{"status":"ok","timestamp":1715503466975,"user_tz":-480,"elapsed":547,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"7bf77629-5d8a-4168-91b2-147d7d8b8ad1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","psnr\n","0.14923164714764361\n","ssim\n","0.004622178607701302\n","mse\n","0.3368351630416108\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-b43277043ffe>:64: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n","  ssim = SSIM(img_cp1, img_cp2, multichannel=True, channel_axis=2)\n"]}]},{"cell_type":"code","source":["#现成图片直接测试\n","image_path = \"./testimg/real\"\n","mask_path = \"./testimg/mask\"\n","img = restore_image2(model,image_path,mask_path)\n","#现场测试\n","image_or = Image.open(\"./testimg/real/test.jpg\")\n","mask = Image.open(\"./testimg/mask/00276.png\")\n","image_path = \"/content/img/uploaded_image.jpg\"\n","IMAGE_PATH = \"/content/img\"\n","mask_path = \"/content/mask/mask_image.jpg\"\n","MASK_PATH = \"/content/mask\"\n","save_path = \"/content/fin\"\n","NOMASK_PATH = \"/content/nomask\"\n","nomask_path = \"/content/nomask/nomask.jpg\"\n","#image_or = Image.open(image_path)\n","mask = \"./testimg/mask\"\n","image_or = \"./testimg/real\"\n","#img = restore_image1(model,image_or,mask)\n","#torchvision.utils.save_image(img, '%s/re.jpg' % (save_path), nrow=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-pAucwxnx6Q","executionInfo":{"status":"ok","timestamp":1715348134341,"user_tz":-480,"elapsed":2214,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"0f5059ea-0060-40ec-a1c7-8c121dc0c29f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-43-913535d19d2e>:56: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n","  ssim = SSIM(img_cp1, img_cp2, multichannel=True, channel_axis=2)\n"]},{"output_type":"stream","name":"stdout","text":["psnr\n","0.8310472880326607\n","ssim\n","0.019810540851973896\n","mse\n","0.125250146033055\n"]}]},{"cell_type":"code","source":["!pip install gradio==4.28.3"],"metadata":{"id":"9LFxGVrScQrA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716770146423,"user_tz":-480,"elapsed":22541,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"213ed9d1-3d9c-4fbc-e0e7-b696a6318c03"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio==4.28.3\n","  Downloading gradio-4.28.3-py3-none-any.whl (12.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio==4.28.3)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (4.2.2)\n","Collecting fastapi (from gradio==4.28.3)\n","  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio==4.28.3)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.16.0 (from gradio==4.28.3)\n","  Downloading gradio_client-0.16.0-py3-none-any.whl (314 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.4/314.4 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.24.1 (from gradio==4.28.3)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (0.23.1)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (1.25.2)\n","Collecting orjson~=3.0 (from gradio==4.28.3)\n","  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (24.0)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (2.0.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (2.7.1)\n","Collecting pydub (from gradio==4.28.3)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart>=0.0.9 (from gradio==4.28.3)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (6.0.1)\n","Collecting ruff>=0.2.2 (from gradio==4.28.3)\n","  Downloading ruff-0.4.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio==4.28.3)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio==4.28.3)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Collecting typer<1.0,>=0.12 (from gradio==4.28.3)\n","  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (4.11.0)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.28.3) (2.0.7)\n","Collecting uvicorn>=0.14.0 (from gradio==4.28.3)\n","  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.0->gradio==4.28.3) (2023.6.0)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.0->gradio==4.28.3)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.28.3) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.28.3) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.28.3) (0.12.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.28.3) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.28.3) (2024.2.2)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio==4.28.3)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.28.3) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.28.3) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==4.28.3)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.28.3) (3.14.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.28.3) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.28.3) (4.66.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.28.3) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.28.3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.28.3) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.28.3) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.28.3) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.28.3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.28.3) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.28.3) (2024.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.28.3) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.28.3) (2.18.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==4.28.3) (8.1.7)\n","Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio==4.28.3)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==4.28.3) (13.7.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==4.28.3)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio==4.28.3)\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio==4.28.3)\n","  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio==4.28.3)\n","  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio==4.28.3)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.28.3) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.28.3) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.28.3) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.28.3) (0.18.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.28.3) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.28.3) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.28.3) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio==4.28.3) (1.2.1)\n","Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio==4.28.3)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio==4.28.3)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio==4.28.3)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio==4.28.3)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.28.3) (3.3.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.28.3) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=d6ee6ee648b37c122964b14e0df981b884c681587b790d5189bb628b6c5b3601\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.9.4\n","    Uninstalling typer-0.9.4:\n","      Successfully uninstalled typer-0.9.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.28.3 gradio-client-0.16.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.5 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","import cv2\n","import numpy as np\n","import PIL\n","from PIL import Image, ImageOps\n","import os\n","\n","\n","title_center = \"<h1 style='text-align: center;'>基于深度学习的图像修复</h1>\"\n","\n","\n","image_path = \"./content/img/uploaded_image.jpg\"\n","IMAGE_PATH = \"./content/img\"\n","mask_path = \"./content/mask/mask_image.png\"\n","MASK_PATH = \"./content/mask\"\n","save_path = \"./content/fin\"\n","NOMASK_PATH = \"./content/nomask\"\n","nomask_path = \"./content/nomask/nomask.jpg\"\n","if os.path.exists(IMAGE_PATH) is False:\n","    os.makedirs(IMAGE_PATH)\n","if os.path.exists(MASK_PATH) is False:\n","    os.makedirs(MASK_PATH)\n","if os.path.exists(save_path) is False:\n","    os.makedirs(save_path)\n","if os.path.exists(NOMASK_PATH) is False:\n","    os.makedirs(NOMASK_PATH)"],"metadata":{"id":"9SEBlFWz-_RA","executionInfo":{"status":"ok","timestamp":1716770148886,"user_tz":-480,"elapsed":2474,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"collapsed":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model_use = loadmodel_set(6)"],"metadata":{"id":"7Q69aHQnBvJt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716770199446,"user_tz":-480,"elapsed":50563,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"16e042dd-115b-498d-c334-ae5e34f56ea1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["csa_net\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:03<00:00, 153MB/s] \n","/content/drive/MyDrive/csa/CSA3/models/CSA.py:25: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n","  self.input_A = self.Tensor(opt.batchSize, opt.input_nc,\n"]},{"output_type":"stream","name":"stdout","text":["initialize network with normal\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/csa/CSA3/models/networks.py:53: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  init.normal(m.weight.data, 0.0, gain)\n","/content/drive/MyDrive/csa/CSA3/models/networks.py:63: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  init.constant(m.bias.data, 0.0)\n"]},{"output_type":"stream","name":"stdout","text":["initialize network with normal\n","initialize network with normal\n","initialize network with normal\n","---------- Networks initialized -------------\n","UnetGeneratorCSA(\n","  (model): UnetSkipConnectionBlock_3(\n","    (model): Sequential(\n","      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): UnetSkipConnectionBlock_3(\n","        (model): Sequential(\n","          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","          (1): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n","          (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (6): UnetSkipConnectionBlock_3(\n","            (model): Sequential(\n","              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","              (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n","              (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","              (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","              (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","              (6): CSA(\n","                (model): Sequential(\n","                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                  (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n","                  (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","                  (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                  (5): CSA_model(threshold: 0.3125 ,triple_weight 1)\n","                  (6): InnerCos(skip: True ,strength: 1)\n","                  (7): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                  (8): UnetSkipConnectionBlock_3(\n","                    (model): Sequential(\n","                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n","                      (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","                      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                      (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                      (6): UnetSkipConnectionBlock_3(\n","                        (model): Sequential(\n","                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n","                          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","                          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                          (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                          (6): UnetSkipConnectionBlock_3(\n","                            (model): Sequential(\n","                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n","                              (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                              (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","                              (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                              (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                              (6): UnetSkipConnectionBlock_3(\n","                                (model): Sequential(\n","                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n","                                  (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                                  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","                                  (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                                  (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                                  (6): UnetSkipConnectionBlock_3(\n","                                    (model): Sequential(\n","                                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n","                                      (2): ReLU(inplace=True)\n","                                      (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                                      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                                    )\n","                                  )\n","                                  (7): ReLU(inplace=True)\n","                                  (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                                  (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                                  (10): ReLU(inplace=True)\n","                                  (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                                  (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                                )\n","                              )\n","                              (7): ReLU(inplace=True)\n","                              (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                              (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                              (10): ReLU(inplace=True)\n","                              (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                              (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                            )\n","                          )\n","                          (7): ReLU(inplace=True)\n","                          (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                          (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                          (10): ReLU(inplace=True)\n","                          (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                          (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                        )\n","                      )\n","                      (7): ReLU(inplace=True)\n","                      (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                      (10): ReLU(inplace=True)\n","                      (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                      (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                    )\n","                  )\n","                  (9): InnerCos2(skip: True ,strength: 1)\n","                  (10): ReLU(inplace=True)\n","                  (11): ConvTranspose2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","                  (12): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                  (13): ReLU(inplace=True)\n","                  (14): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                  (15): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                )\n","              )\n","              (7): ReLU(inplace=True)\n","              (8): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (9): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","              (10): ReLU(inplace=True)\n","              (11): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","              (12): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","            )\n","          )\n","          (7): ReLU(inplace=True)\n","          (8): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (9): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (10): ReLU(inplace=True)\n","          (11): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","          (12): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        )\n","      )\n","      (2): ReLU(inplace=True)\n","      (3): ConvTranspose2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n",")\n","Total number of parameters: 77692291\n","UnetGenerator(\n","  (model): UnetSkipConnectionBlock(\n","    (model): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): UnetSkipConnectionBlock(\n","        (model): Sequential(\n","          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","          (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (3): UnetSkipConnectionBlock(\n","            (model): Sequential(\n","              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","              (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","              (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","              (3): UnetSkipConnectionBlock(\n","                (model): Sequential(\n","                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                  (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                  (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                  (3): UnetSkipConnectionBlock(\n","                    (model): Sequential(\n","                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                      (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                      (3): UnetSkipConnectionBlock(\n","                        (model): Sequential(\n","                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                          (3): UnetSkipConnectionBlock(\n","                            (model): Sequential(\n","                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                              (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                              (3): UnetSkipConnectionBlock(\n","                                (model): Sequential(\n","                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n","                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                                  (2): ReLU(inplace=True)\n","                                  (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                                  (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                                )\n","                              )\n","                              (4): ReLU(inplace=True)\n","                              (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                              (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                            )\n","                          )\n","                          (4): ReLU(inplace=True)\n","                          (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                        )\n","                      )\n","                      (4): ReLU(inplace=True)\n","                      (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                      (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                    )\n","                  )\n","                  (4): ReLU(inplace=True)\n","                  (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","                  (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","                )\n","              )\n","              (4): ReLU(inplace=True)\n","              (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","              (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","            )\n","          )\n","          (4): ReLU(inplace=True)\n","          (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","          (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        )\n","      )\n","      (2): ReLU(inplace=True)\n","      (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (4): Tanh()\n","    )\n","  )\n",")\n","Total number of parameters: 54419459\n","NLayerDiscriminator(\n","  (model): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n","    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n","  )\n",")\n","Total number of parameters: 2766529\n","PFDiscriminator(\n","  (model): Sequential(\n","    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (5): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","  )\n",")\n","Total number of parameters: 10487296\n","-----------------------------------------------\n","model [CSAModel] was created\n","load model successfully!\n"]}]},{"cell_type":"code","source":["import time\n","def restore_image(image_or, mask):\n","      image_or = cv2.cvtColor(image_or,cv2.COLOR_BGR2RGB)\n","      cv2.imwrite(image_path, image_or)\n","      image_or = Image.open(\"./content/img/uploaded_image.jpg\")\n","      mask = mask['layers'][0]\n","      mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n","      cv2.imwrite(mask_path, mask)\n","      iterator_test = loadimg(IMAGE_PATH, MASK_PATH)\n","      width = image_or.width\n","      height = image_or.height\n","      model = model_use\n","      repaired_image=inpaint(iterator_test,model,height,width)\n","      repaired_image = Image.open(\"./content/fin/re.jpg\")\n","      mask = Image.open(\"./content/mask/mask_image.png\")\n","      break_image = Image.open(\"./content/fin/break.jpg\")\n","      #torchvision.utils.save_image(repaired_image, '%s/re.jpg' % (save_path), nrow=1)\n","      return repaired_image,break_image, mask\n","def restore_image1(image_or):\n","      image_or = cv2.cvtColor(image_or,cv2.COLOR_BGR2RGB)\n","      cv2.imwrite(image_path, image_or)\n","      image_or = Image.open(\"./content/img/uploaded_image.jpg\")\n","      iterator_test = loadimg(IMAGE_PATH, NOMASK_PATH)\n","      width = image_or.width\n","      height = image_or.height\n","      model = model_use\n","      repaired_image=inpaint(iterator_test,model,height,width)\n","      fin_image = Image.open(\"./content/fin/re.jpg\")\n","      break_image = Image.open(\"./content/fin/break.jpg\")\n","\n","      #return repaired_image\n","      #torchvision.utils.save_image(repaired_image, '%s/re.jpg' % (save_path), nrow=1)\n","      return fin_image,break_image\n","\n","def restore_image3(image_or, mask):\n","      image_or = cv2.cvtColor(image_or,cv2.COLOR_BGR2RGB)\n","      cv2.imwrite(image_path, image_or)\n","      image_or = Image.open(\"./content/img/uploaded_image.jpg\")\n","      cv2.imwrite(mask_path, mask)\n","      iterator_test = loadimg(IMAGE_PATH, MASK_PATH)\n","      width = image_or.width\n","      height = image_or.height\n","      model = model_use\n","      repaired_image=inpaint(iterator_test,model,height,width)\n","      fin_image = Image.open(\"./content/fin/re.jpg\")\n","      break_image = Image.open(\"./content/fin/break.jpg\")\n","\n","      #return repaired_image\n","      #torchvision.utils.save_image(repaired_image, '%s/re.jpg' % (save_path), nrow=1)\n","      return fin_image,break_image\n","\n","def te(inputs,image):\n","  image = image['layers'][0]\n","  return inputs,image\n","\n","def restore_image000(image_or):\n","      fin_image = Image.open(\"./content/fin/re.jpg\")\n","      return fin_image\n","\n","gr.close_all()\n","\n","iface1 = gr.Interface(\n","    fn=restore_image1,\n","    inputs=gr.Image(label=\"上传要修复的图像\"),\n","    outputs=[\"image\",\"image\"],\n","    title=title_center,\n","    description=\"随机损坏修复\",\n","    )\n","iface2 = gr.Interface(\n","    fn=restore_image,\n","    inputs=[\n","        gr.Image(label=\"上传要修复的图像\"),\n","        gr.ImageEditor(label=\"涂改mask（可选）\")\n","    ],\n","    outputs=[\"image\",\"image\",\"image\"],\n","    title=title_center,\n","    description=\"涂改损坏修复\",\n","    )\n","\n","iface3 = gr.Interface(\n","    fn=restore_image3,\n","    inputs=[\n","        gr.Image(label=\"上传要修复的图像\"),\n","        gr.Image(label=\"mask\")\n","    ],\n","    outputs=[\"image\",\"image\"],\n","    title=title_center,\n","    description=\"涂改损坏修复\",\n","    )\n","\n","tabbed_interface = gr.TabbedInterface([iface1, iface2, iface3], [\"随机损坏修复\", \"涂改损坏修复\", \"指定损坏\"])\n","tabbed_interface.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":764},"id":"Git-ZvdAkvSV","executionInfo":{"status":"ok","timestamp":1716770202982,"user_tz":-480,"elapsed":3539,"user":{"displayName":"郝赟","userId":"01912104721301990604"}},"outputId":"15b4379b-db33-4d9c-d1f6-effc948c874d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["IMPORTANT: You are using gradio version 4.28.3, however version 4.29.0 is available, please upgrade.\n","--------\n","Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","IMPORTANT: You are using gradio version 4.28.3, however version 4.29.0 is available, please upgrade.\n","--------\n","IMPORTANT: You are using gradio version 4.28.3, however version 4.29.0 is available, please upgrade.\n","--------\n","IMPORTANT: You are using gradio version 4.28.3, however version 4.29.0 is available, please upgrade.\n","--------\n","Running on public URL: https://aa02c45ff9e0aae0ff.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://aa02c45ff9e0aae0ff.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":[],"metadata":{"id":"Dt4E5s4B74rv"},"execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda env:pytorch]","language":"python","name":"conda-env-pytorch-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}